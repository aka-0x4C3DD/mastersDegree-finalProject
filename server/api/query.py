"""
Query processing endpoints
"""
import logging
import re # Import the regular expression module
from flask import Blueprint, request, jsonify
from server.model_management import ModelManager
from utils.web_scraper import search_medical_sites # Use the refactored web scraper entry point
# Import the LLM-based keyword extraction function
from utils.file_processor.medical_terms import extract_search_keywords

logger = logging.getLogger(__name__)
query_bp = Blueprint('query', __name__)

# Keep model_manager in the signature
def register_query_routes(app, model_manager: ModelManager, device_config):
    """Registers query-related API routes."""

    @query_bp.route('/query', methods=['POST'])
    def handle_query():
        """Handles user queries, optionally searches web, and generates response."""
        data = request.get_json()
        if not data or 'query' not in data:
            return jsonify({"error": "Missing query in request"}), 400

        user_query = data['query']
        search_web = data.get('search_web', False) # Default to False if not provided

        logger.info(f"Received query: '{user_query[:100]}...', Search web: {search_web}")

        web_results = []
        search_context = ""

        if search_web:
            try:
                # --- Keyword Extraction Step using LLM ---
                search_keywords = extract_search_keywords(user_query, model_manager)
                if not search_keywords:
                    logger.warning("No keywords extracted via LLM, falling back to original query for web search.")
                    search_term = user_query
                else:
                    search_term = search_keywords
                # --- End Keyword Extraction ---

                logger.info(f"Performing web search with term: '{search_term}'")
                web_results = search_medical_sites(search_term, max_results=3)

                if web_results:
                    search_context = "\n\nRelevant information from trusted sources:\n"
                    for i, result in enumerate(web_results):
                        search_context += f"\nSource {i+1}: {result.get('source', 'N/A')}\n"
                        search_context += f"Title: {result.get('title', 'N/A')}\n"
                        search_context += f"Content: {result.get('content', 'N/A')}\n"
                    search_context += "\n---\n"
                    logger.info(f"Added context from {len(web_results)} web results.")
                else:
                    logger.info("Web search returned no results.")

            except Exception as e:
                logger.error(f"Error during web search: {str(e)}", exc_info=True)
                search_context = "\n\n[Web search encountered an error and could not retrieve information.]\n"


        # Construct the prompt for the LLM
        prompt = f"User Query: {user_query}{search_context}\nBased on the above query and potentially relevant information, please provide a comprehensive and helpful medical assistant response. If web information was provided, synthesize it with your knowledge but prioritize accuracy and safety. State if information comes from external sources."

        logger.debug(f"Constructed prompt for LLM (first 200 chars): {prompt[:200]}...")

        try:
            # Generate response using the model manager
            model_response_raw = model_manager.generate_response(prompt)

            # --- Clean up the response ---
            # Remove potential prompt remnants
            cleaned_response = re.sub(r"User Query:.*?\n", "", model_response_raw, flags=re.IGNORECASE | re.DOTALL).strip()
            cleaned_response = re.sub(r"Based on the above query.*?\n", "", cleaned_response, flags=re.IGNORECASE).strip()
            # Remove potential internal generation info (adjust pattern if needed)
            cleaned_response = re.sub(r"Generated by .*? on .*?\n", "", cleaned_response, flags=re.IGNORECASE).strip()
            # Remove leading boilerplate if it appears
            if cleaned_response.lower().startswith("assistant:"):
                 cleaned_response = cleaned_response[len("assistant:"):].strip()
            # --- End cleanup ---

            # Prepare final response structure
            response_data = {
                "query": user_query,
                "response": cleaned_response, # Use the cleaned response
                "web_results": web_results, # Include web results for display
                "model_name": model_manager.model_path.split('/')[-1] if model_manager.model_path else "Unknown", # Add model name
                "device_used": device_config['main_device'] # Add device info
            }

            logger.info("Successfully generated and cleaned response.")
            return jsonify(response_data), 200

        except Exception as e:
            logger.error(f"Error generating model response: {str(e)}", exc_info=True)
            return jsonify({"error": "Failed to generate response from model"}), 500

    app.register_blueprint(query_bp, url_prefix='/api')
